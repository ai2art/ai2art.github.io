---
title: 随笔
---

# {{ page.title }}


### AI 的本质“只是”拟合吗

有人说AI就是拟合，但对于“智能”这样复杂的问题，除了拟合、模拟数据表象，还有更好的方式吗？

人类儿童学习本质上不是模仿模拟吗？

AI本质要研究的就是该用怎样的“结构”去拟合大数据，这个“结构”可以说就是智能本身，从无神论的角度来看，人的大脑也无非是这种“结构”的一个物理实现。

 从现实可行性来说，能够拟合大数据的“结构”，能够得到有效预测结果的“结构”，不借助深入的数学知识是很难找到的，这是一项艰深，而不知边界在何处的学科领域。 

AI 没有那么神秘，因为从数学的形式理论上看，AI是拟合； 但AI的重点不是拟合，而是那个可以有效表征大数据的具体“结构”，也就是“智能”。在AI领域，形式理论常常意义并不大，更重要的具体的工程实践，至少形式理论不能脱离工程实践。

talks are cheap，轻蔑地说AI只是拟合，一般来说是对这项研究活动缺少深入认知和实践后的傲慢，或者是对AI已经实现的惊人结果视而不见，缺少感知力和想象力。


### 聪明人 和 傻x

“聪明人”是绝大多数，大多数坐在办公室里朝九晚五“兢兢业业”的人都是聪明人。他们做的每一个选择，从概率论的角度来说，都是明智的。 

正如同从概率的角度说，绝大多数变异基因的结果都是肿瘤细胞，都会被自然选择所淘汰。 但总有一些基因要变异，也总有一小部分人宁愿做“傻x”，像傻x一样一意孤行，像傻x一样不肯妥协，而且显然这样的人觉大多数最终也的确是“傻x”……但有时候“牛x”和“傻x”就差那么一点点，挺过去了就是“牛x”，挺不过去就是“傻x”， 一切都很公平...

### 人与机器

如果我们不是不可知论者，那么人本身就是一个“图灵机”，就几乎是个必然的事实，人面对大自然时，内存是非常有限，像一个工作在纸带上的打点机，hadoop的思想也像打点机器，纸带不动，机器动。我们无法完整感知整条纸带，正如同应该没有任何一个人类个体完整理解计算机的制作工艺和工作原理，但人类还是将计算机制作了出来。

站在大自然的角度来说，人也不过是半衰期相对长一点的耗散现象而已。人们努力生活，和大草原上的动物努力生存, 和湍流中短暂的涡旋，或许并没有本质区别，都是某种耗散现象的自我维持。在进化的求解过程中，大自然生物千姿百态，又何尝不是无数种“局部最优解”呢。

### 进化的不完全性

当一个成年人沉迷玩斗地主等简单游戏时，是一种胜负心在作祟，这和青少年莫名其妙的逆反心理，小孩子争强好胜的心理倾向都是一样的，不是因为游戏本身有趣，而是人性非理性的一面，或者称其为弱点。

昨晚的一个梦境让我觉得美好，或许是体验到爱情不只有阴暗的一面，也有美好的一面，对一朵花的沉迷，让人想要排斥不洁的想法，或许这从进化上也是合理的，毕竟从进化来说爱情的出现是为了繁衍生命，而纵情声色并不完全符合这种本质诉求。

人类对非生育性行为的沉迷，性视频、不洁想法的蛊惑性，手淫自渎等行为的出现，是进化不完全的体现，进化原理鼓励对生育和遗传的向往，但大自然需要将这个“目的” 落实到具体措施中，于是人们直接沉迷于性行为本身，迷恋于性表象本身，向往多巴胺的刺激，这些是理性需要克服的，也是理性存在的意义。

### 关于技能的学习

我们通常可以将作品创作的技术分为两个环节，第一个是模板、范式；他可以勾勒出作品的粗线条；例如折纸的base结构、或代码目录结构，MVC架构等等；第二个是各种零碎的trick、技能；例如代码方式、软件shortcut、折纸的微结构技巧等等，他们是对艺术品创作过程的两个不同维度的抽象和投影，只有这个两个环节都熟悉了，才能够做出漂亮的东西
学习过程的第一步通常是闲逛、然后不知道什么时候你会突然发现线索；如果你的目的性很强，这一步通常是很折磨人的，因为你无法预期闲逛的结果和发现线索需要的时长，这也是有游戏化教育的意义所在，因为这让大家乐在其中，而不太有目的性，当然对于一些门槛较高的游戏，例如还原魔方，闲逛很久也无进展，这时你应该寻求专业的帮助，当然对于一个学习者，u are supposed to seek help when in need. 并且在互联网时代，这种专业帮助的获得其实门槛已经降了很多

互联网时代，是一个信息壁垒不高的时代，那么剩下的主要是行动壁垒。

普通人最难度过的对未知的探索期，我们下意识地拖延行动，害怕那种迷茫，或者潜意识相信很难完成，想要放弃，怎样尽量快速度过这个犹豫期，迅速上手，get hand dirty 能极大提高人的效率。

先get hand dirty，然后才能get hand clean。


### 理性的不完备性

理想情况下，胆大和谨慎不是矛盾的，胆大是目标层面，谨慎是实现目标的策略层面。 但现实情况常常复杂很多，我们常常很难找到目标和策略的边界。 意识的复杂也远高于机器，人可能在实践过程中，目标本身产生偏离，例如放弃，甚至是下意识地放弃，同时人们也不可能严格评估现状和目标的价值，因此谨慎可能是胆小怕事，胆大也可能是荒唐鲁莽，它没有严格标准，因此没有silver bullet，甚至无法评估胆大本身是不是缺点，谨慎是否是优点。

在很多实际情况中，我们都像“麦克斯韦妖”问题那样，忽略了认知主体的代价，比如说我们劝别人不要逃避，要勇敢面对问题的时候，事实上我们常忽略了个体能量的有限性，而处理问题是需要付出的精力能量的，显然如果是一件重要的事，当然值得费精力去解决，但不重要的事，可能逃避就是个好选择，当然什么是“重要/不重要”的判断，本身有主观性。 付出的代价怎样算高，对于个体也有差异性。 再比如说“追求极致”也是一样，有人说：毁掉一个年轻人的最好办法，是教这个年轻人追求极致。这话其实在很多context下没问题。 

所以一切道理都要在context中考量，
而这种context中的考量永远不像“标语”一样干脆有力，但干脆有力的未必一定是良药，毒品也一样药效猛烈。 这是语言表达的局限性，也是“有限理性”的具体表现。

这是理性的“哥德尔定理”，我们看到了问题的存在，但却没有一个干脆的答案。

### 关于web3.0

元宇宙等概念无疑是炒作，或者是“新瓶装老酒”。但web3.0确是一个真正的技术方向，只是到来早晚的问题。

web3.0的本质意义在于怎样提高民主的效率。民主从来不是高效的，但却是相对安全的，集权反之。这主要是非技术层面的原因。

web2.0之前的软件无疑都是都是“集权”架构的，这符合技术的演化路径，因为我们首先要实现功能，然后才谈得上关注安全。 web2.0 关注的是功能实现，因此效率优先是合理的选择。

在基本功能已经实现，算力出现剩余的前提下，web3.0 是一个必然的发展方向，这是为了夯实互联网技术的基建，预防集权可能引起的灾变。而显然这项技术在西方会更受重视。

### 做好自己

最近听了某独立媒体对以岭药业的解读，感觉是符合逻辑的。 有利益的地方，就有江湖，无论是庙堂之高，还是江湖之远…太阳之下无新事。 每次听到这样的事情，难免心情浮躁。 

虽然我们为了安身立命，常怀蝇营狗苟之心，但真正有趣的事情，从来就和利益无关。 因为这些或那些无法改变的事情而心情浮躁，不过是自己目光浅了，灵魂浊了，一叶障目而已。

“我们不过是宇宙里的尘埃,时间长河里的水滴, 所以大胆去做不要怕, 没有人在乎,就算有人在乎,人又算什么东西。”

做好自己就好，不论是庙堂之高，还是江湖之远，你无法改变什么，也无需改变什么。

### 不纠结 

人是一种常会自我怀疑的物种，这是高等智慧体的特征，他让人具备反省自纠错能力，但副作用也不小，尤其是像你这样常不自信的人。

比如说当我们读源码时，觉得代码结构写得比较晦涩，我们有时会像小学生一样怀疑是不是作者有什么深意，是不是自己功力不够理解不透…但其实代码风格哪有什么对错，最佳实践也常常不是最佳，甚至源作者考虑的事情也不是你应该考虑的，这和你无关。一切实践都有context ，如果不适合你的场景那就不是最佳。 表象既内涵，需要多点自信，更何况就算有再好的东西，消化理解不了也不是你的，不要纠结于权威或者最佳实践。 


代码要不要重构，也极其考验一个工程师的判断能力，到底是图一时方便，因循已有接口，改写现有模块，还是重构旧代码适合新思路，这也是工程师常纠结的地方…认真处处是学问，我想代码的延展和人生的很多选择一样，遇到这种问题，我们能做的只有按个暂停键，喝杯咖啡，摈除杂念，然后在心底问自己究竟怎样才是正确的路，如果是该迁就的那就和光同尘不拘小节，如果是该决断的，那就推倒地基在所不惜，最可怕得是不清楚自己想要的到底时什么，糊涂账越积越多，错误越累越高，到头来怎样的选择都是纠结和错误。做到不纠结不容易，写代码也是一种修行，设计更加模糊的人生则更难，因为人生不能预演更没有标准答案，不纠结需要莫大的决心，这是孤独面对整个世界的勇气，这样的人似乎很洒脱也注定很艰辛，这没有对错，仅仅是选择，选择不给自己任何借口而已。


### 大胆假设，小心求证

对于一名优秀工程师最难把握的分寸是敬畏之心。 我们常看到一些看似简单落后的方案，比如动画界的blendshape，看似粗糙但却是业界标准，哪怕AI已经这么应用深入，也几乎没听说过能取代blendshape，这是为什么呢，我想可能和blendshape的高度可控性有关，这也许是长期实践后的业界选择吧，但这种业界选择一定不能被打破吗，当然不是不可能，但打破它绝对要比想象中困难，这是需要在意料之中的。就好像猎鹰1号的发射一样，似乎民营比官方更高效是一个共识，并且技术储备对于当时的spaceX似乎是没有问题的，但理论终归是理论，猎鹰1号也失败了3次，不知道第四次成功的运气成分有多高，但如果没有孤注一掷的坚持几乎肯定等不到最后的希望。 小心求证的道路是艰苦卓绝的，但如果真那么容易成功，那条路不是应该被前人早走过了吗，你真的相信有谁比别人能聪明多少吗，荆棘之路不是说一说而已，大家拼的是胆识和决心。创新几乎注定意味着失败，并且不是一次，而是很多次。所以真正的创新之路要么是初生牛犊不怕虎，生猛闯出来的；要么光脚不怕穿鞋逼出来的；要么是疯人院跑出来的……

### 为什么大模型越来越流行

仅仅是一种体量越来越越大的差别吗？ 我想显然不是，这是因为AI的应用正逐步由以前的识别、判断，向发现、生成转变。 以前AI解决的问题是封闭性的问题，而现在AI要解决的是开放性的问题，以前要答的选择题，现在要解的是问答题……而这种问题本质上需要AI的“知识面”很广，因此AI模型必须要是“大模型”，这不是一种量变，而是一种应用范式的质变。


### 为什么语言模型很重要

1. 语言是Interface，是人类和机器最直接的沟通方式，这里语言狭指可以被人类容易理解的语言，例如自然语言，高级编程语言，数学形式记号，而不包括汇编等机器语言（当然这里的过渡有些不严谨）

2. 语言是思维的表现形式，人类语言本质上是描述人类思维的，是让思维、经验等跨越时空沉淀下来，并使之可以在人类之间传递的工具；如果没有语言，显然知识无法传递、积累；甚至就算不需要传递，现代人的大脑也许脱离了语言本身就无法思考（先天聋哑人的思维方式是不是会和我们有很大不同，或者思考能力也会受限很多？）


3. 正是因为语言是描述思维的，因此语言本身甚至能够干预思维的过程，例如好的语法规则、编程方式有助于我们拔丝抽茧解决问题，反之则会让问题更加迷雾重重

4. 人类语言的信息传递速度是非常低的；机器可以在脱离语言的状态下干很多事情；但如果我们要让一个抽象过程可以被人类大脑理解，我们还是不得不把它转译成语言，因为我们的思考是离不开语言的（思考时常像自己和自己对话的感觉，有个声音在脑袋里说话的感觉）


### 另一个视角看webapp

webapp 是服务端A，先把一段程序a先传送给客户端B，这个程序a作为服务代理，接收A提供给B的服务。

也就是说，A 先把对讲机通过快递送给B，然后再和B通话，自产自销。 

（原生手机应用，相当于A把对讲机先放到一个公共集散地（应用商店），然后B自己去取；
web应用相当于，A和B没有做任何事前准备，A临时决定给B快递一个对讲机，然后对话完之后，对讲机也随后被销毁，当然web应用也能和手机应用一样停留在浏览器，但这不算是web应用的典型特点）

naive的想法总认为A和B要有先天默契，才能交互。 但这种模式至少在应用层来看，B没有任何投入，而能够和A形成默契交互。

当然A和B的先天默契体现在http底层，而不是在应用层。

司空见惯的事物换个角度看，也常能感到奇特之处。

### 无感

之所以要知行合一，是因为很多时候，认知直接来源于实践，我常惊叹于在各个领域都有那么多智者有着丰富的洞察，不论是技术、艺术还是生活。 分析这些人的履历，会发现这些洞察常源于他们自身经历，我们认为的一个犀利观点，再怎样犀利，也不过只是观点，而在他人而言却可能是血淋淋的教训。

很多时候思想贫瘠，是因为经历的匮乏，未经一事，不涨一智。 

人与人之间的隔阂，常常不是同意或反对，不是观点之争，而是“无感”。

经历之外的认知，我们常是无感的。 同样的道理也可以用在同理心上，未经他人事，莫劝他人善，不要过高估计自己的理解能力，也不要过高估计他人的理解能力。

### 做一个“好战分子”

年底了，写一点年终总结吧。 2022年是特殊的一年，是艰辛痛苦的一年，不是因为外在的磨难，而是因为内心的挣扎与困惑。 但是这些都不足为外人道也，哪怕是落于文字也显得矫情。我想我的状态曾陷入了一个莫名的陷阱，至今想起来仍感到虚脱，感到不寒而栗，但这种状态绝不能再延续下去，我想我终归是一个理性的人，毕竟我有太多理由坚持下去。曾经有位哲人说过“死亡是一个注定要降临的节日”，在节日降临前，我们不妨去做点什么，诚然我并不相信坚强一定比脆弱更高贵，但我相信坚强应该比脆弱更理性，而我终归是理性的。 面对时常恶作剧般的人生，面对渺小的自我，不妨做一个好战分子吧。只有做个好战分子，才能让人真正有勇气面对一切艰难险阻，才能让人放下一切无谓的自尊心，才能让人真正乐观起来，才能让人像一滴水融入生活的深渊，泥沙俱下，和光同尘。

### 关于才华

才华不是一个绝对概念。比如说大刘如果是一个传统作家，一定是一个糟糕的作家。 因为他不擅长刻画人物；如果是一个工程师，也估计是一个糟糕的工程师，因为他的思维太不严谨。 但他不严谨的思维，不深入的科学理解，让他恰好可以广泛涉猎，敢于想象，并免去了真实物理的桎梏，描绘出一个亦真亦假壮丽恢弘的科幻世界，让其他人望尘莫及。 这不能不说是一种才华。 有时候就算老天爷赏饭吃，也需要找对那只碗。

### 克服社恐

自媒体还是要坚持一下的，至少有三点价值：

1. 帮助你克服社恐
2. 练习表达能力，强化表达意愿
3. 练习时间管理能力

在这个意义上，去做自媒体，而不要被一时的情绪或者热度所左右。

### <飞鸟与鱼>

当一个故事足够抽象，它就变得像每个人的故事。

### 项目型思维

项目型思维和研发型思维是完全不同的，研发型思维是问题导向，专注于问题本身，需要死磕精神，当然这种死磕是有风险的，因为并不是所有问题都有答案；项目型思维，则是问题不论有没有答案，都必须要有结论，因为项目型思维专注的不是问题本身，而是向项目负责，如果问题不当，那就处理下一个问题，而死磕对项目来说很多时候不是一个理性选择，项目型思维不容易陷入死胡同，但更考验一个人的管理能力，情绪管理、时间管理、风险管理。 这两者思维的冲突是必然的，但什么样的角色就需要什么样的思维，研发人员需要有研发型思维和死磕精神，如果不具备这种精神，就不会有真正的核心技术突破；而管理人员需要有项目型思维，如果不能对项目整体负责，做好风险把控，那就不是一个合格的管理人员。

### 为什么中国没有真正的创新

现代科技中国几乎没有从0到1的创新，拿ChatGPT 为例，由于种种原因，不论是资本还是研发，中国人在ChatGPT出现之前是没有耐心等待 GPT1、GPT2、GPT3 迭代的；西方的创新来自真正的兴趣和偏执，不论是Musk还是Sam都是偏执狂，如果不偏执，很难去想，也很难脚踏实地去做这些异想天开的项目，而这些项目在中国是不会有生存土壤的，研发没有勇气，资本缺少耐心。 中国人的创新更多是出于危机感，出于“大国重器”，出于“举国体制”，是1到100的创新，而绝非从0到1的创新

### 有血性

活着要有血性，情情爱爱，低眉怨思这些成不了事，要有斗志，找回自己，就当自己已经死过一次！

晚熟一点也不用着急。不要慌乱，也不要停步，人生是一场持久战，看谁笑到最后。


### AIGC

AIGC 还没有到繁花盛开的时候，需要寻找大树和小草。大树是资源支持，1.算法突破，底层研发，比如质量更好，清晰度更高，美感更好，劣图出现更少；生成更快，算力消耗更少；可控性更好，连续性更好，意图命中更精准，渐进优化更快；2 培养生态，创造开放平台，建立和优秀生产者的良性互动，培养新生代生产者的习惯，打通产业下游如作品版权，NFT 交易平台。小草是细分场景的落地，这个场景一定是对Aigc 不成熟现状容忍度较高的场景，比如教育行业，指导作文，指导绘画。

AIGC 不成熟的现状很难短时间改变，在严肃的商业场景例如广告等行业，AIGC仍只能作为草图来使用，AIGC突破了草稿的水平线，但还没有突破成品的水平线，进一步提高AI生成精度的技术难度显然会越来越高，而我不认为目前AIGC的技术框架可以突破成品线。 在这个认知前提下，落地AIGC有几个明确的方向：

1. 核心算法研发和优化，需要耐心和输血，这是大公司的赛道，小公司很难存活
2. 小公司寻找适合AIGC水平线的casual业务方向
3. 在serious业务方向，降低AIGC和人工“精处理”的合作门槛，业务标准化，建立从草稿到成品过程的顺畅“流水线”。 


### 做好自己

做好自己该做的，至于这个世界领不领情不重要，生活原本就有太多不可控的因素，没有那么多因为所以。 更何况你该做的可能都没做好，不用一厢情愿的担心别人，没准最该担心的是你自己。 
成年人的蜕变在于认清自己的局限，在于不再把自己的意愿和认知强加给别人，在于不再向往当一个自娱自乐的堂吉诃德。 单丝难成线，浓墨不成画，脑中全是幻想，哪有心思面对生活中的琐事，但生活就是琐事组成的，能把自己的琐事收拾好，就已经不错了。 

### 路要自己走

虽然很多底层认知并不复杂，但到商业落地却有大量经验性知识和操作性细节需要掌握，这些常常是琐碎无趣的。技术创业人，天生是一个尴尬的角色，一方面你只想做技术，做单纯有趣定义明确的事情，但这样的专家路线无法实现技术价值的最大化，所以你又不想完全投入精力变成一个技术专家，你只能像一个小学生一直走在未知的道路上。自由从来都是最稀缺的资源，而你现在的焦虑究其根本原因是，你和大多数人一样随遇而安，一直没有强烈的目标意愿，没有尽早探索出self-sustainable的模式……这是你认知的问题，从没有捷径可走，没有交过的学费，终归要自己交。 没有走过的路，终归要自己走。

### AGI 真的实现了吗

GPT所涌现出来的“乌鸦”能力，是不是 transformer有二阶主题、甚至更高阶主题的拟合所引起的？而这种“乌鸦”能力，是不是真的也是人类智能的本质？

GPT所展现出的 in-context learning 能力，是一种自然语言拟合的假象，还是说真的是智能本身？GPT的拟合能力，是不是和训练的序列长度有关？如果GPT的单条训练数据是长篇小说，（当然现实中没有那么多长篇小说），那么是不是说GPT架构就能真正写出有主题的长篇小说？人类智能和机器智能的有效复杂度是不是在一个量级上？ 

不管AGI有没有实现，我们确实在见证一次技术的飞跃。当自然语言成为interface，成为机器算力的终极调度手段，我们仿佛看到一座耸入云端的巴比伦塔，这座高塔不仅要抹平人类语言的差异，也要抹平人类和机器的沟通障碍，GPT的下一个迭代也许是多模态的输入，文字、图像、视频这些维度的差异也似乎必将抹平。 这真是一件不可思议的事情。

### GBT 的特征

1. 通用性，AI技术走向大一统，从多语种到多模态，这是方法论的一次飞跃
2. transformer有效性之谜，我倾向于认为有非常多种结构可以实现transformer的效果，并且效率甚至可能比transformer还要高很多，只是人类现在瞎猫碰上死耗子只发现了这一种有效结构而已。正如物理学中费马定理一样，凡是“巧合”，定有某种更深刻的必然性。
3. 自反馈，RFHF + transformer的高阶拟合能力，GBT 展现出惊人的in-context learning ablility 但自反馈似乎天生是有漏洞、不完备的，没准可以通过“哥德尔定理”，可以证明一定存在有漏洞的prompt
4. AGI 的下一步进化，可以把“自反馈”，进一步玩到极致，这就是“进化”，比如说AI可以连接各类物联设备，让AI真正探索物理世界 （当然这是一件非常危险的事情），甚至AI自己设计实验方案，发现新认知，而不是被动地被喂养数据。 在“图灵测试”意义上，似乎AGI在可预见的未来就和人类趋同了，那么AGI是否有意识，是否值得尊重“人格”，就变成了某种“信仰”问题了…… 我们似乎一只脚已经踏进了科幻世界！
5. 特征涌现，GBT 模型的参数量大到一定程度，发生了一些属性的emergent，这是一个惊人的现象，因为这说明可能大量的有效解藏在了复杂性之中。世界可以用简单的数学去理解，可能只是部分人画地为牢的谬论。 


### GPT应用

GPT类应用，在用户对某项知识有清晰理解可以轻松做出判断，但同时又对该知识的很多具体细节又回忆不起来时可以发挥最大的作用，从这个意义上而言，GPT本质上相当于人脑的扩展内存。 它不像cpu寄存器（人脑）那么高效，但又比硬盘快很多（例如通过搜索或者查阅资料重新复现知识细节） 

大模型是新的“石油”或电能，AI将变成一种通用能力，应用到大量信息处理场景，这将形成一个生态，有负责产油的），有负责深加工的，有负责加油的，有负责管道建设加固的。 于此同时，大量“白领”工作（信息处理类）也会转变，文书人员、设计人员和传统IT工程师将大量消减。

gpt 现在的精度还远没达到直接生成二进制文件的水平，所以他在应用生成领域的实现路径应该是，生成工程师可读的源码，人类在AI辅助下进行单元测试或微小改动形成工程闭环，然后生成应用

GPT的成功象征着经验主义相对于还原主义的胜利，或者说人类在远没有掌握第一性原理之前，就可以在黑箱或者灰箱状态下，将科技能力推向更遥远的地方。

### 文本生成视频

想明白了一个文本直接生成人物视频的可实现路径，想要做一个健壮可用的视频生成引擎，工程量显然是极其繁重复杂的，但种种迹象表明，基于现在的算法底层，这步应该是已经可以实现了，也许未来一年以内会出现类似的AI产品或功能……

### 自我完整

要一遍一遍温习让自己认同自己是“完整”的，只有当一个人相信自己是“完整”的时候，内心才会安定下来，才能静下心来做事情。 把心脏放回自己的胸膛，没有人在乎。这个世界多你一个不多，少你一个不少，做点脚踏实地的事情，别在幻想里执迷。 人其实什么都不是，人生也毫无意义，每个人都明白这个道理，只不过我们头脑的内存太小，只有在夜深人静的时候，才能偶尔full-aware 这种荒诞的感觉。 你只是宇宙角落里一段莫名其妙充满bug的碳基程序而已，别跟自己较劲。

### 未来世界

GPT给我们的印象如果不是幻觉，如果它展现的“智能” 和人类大脑的信息复杂度在一个量级。那么GPT给我们最大的启示是“压缩即智能”，而transformer是对现实世界和人类认知的有效压缩表征，虽然这种表征未必是高效的，也未必和人脑机制有什么直接关系。 工程师视角和layman视角对技术变化往往是两个极端，工程师由于能够看到技术一路走来的“平庸”历程，能够看到被扫到地毯之下的messup, 所以经常会低估技术临界点的到来；而对于layman，由于每项技术对他们来说都像一个小小的奇迹，因此常常过于高估技术的现状。 需要常常切换视角和自我批判，一切从事实出发，不盲信，但也要尽量避免低估新事物的能量。 

“好的问题，是成功的一半”。 在GPT时代，好的问题，是成功的一大半，甚至几乎是全部。当然这里的问题和人类的洞察力和思想力相关，而不是指“prompt engineering”。 我们也许真的在经历一次信息产业的革命，不可思议！

### 创业维艰

对于创业者来说，受限于思想力和行动力，可能选择了并非顺风的目标，但如果没有目标，放弃思考，任何风都不会是顺风，在GPT时代也一样。 这和投资人不同，他在意被投人是否认真思考，但对于这个思考本身是否正确他并不会真正去判断。 因为投资人本质是在赌马，他只要选对赛道，只要有一匹马胜出就可以了。 但创业者必须要思考，他没有资本筹码，有的只是思想，至于这个思想有没有价值，需要通过实践来验证，这是非常功利也非常公平的协作机制。

AI革命让我们处于一个超卷的大时代，大公司有大公司的卷法，小公司有小公司的卷法，每一个普通人也有各自的焦虑，能够经历这次产业革命，是我们这代人的幸运和不幸。与其被时代裹挟，不如去拥抱时代。 

### 关于GPT的思考

1. openai无法成为全球大脑

相比于搜索而言，GPT的输入信息更加敏感，或者说GPT比google更优越的地方在于能够处理更加详细和敏感的信息，如果输入粗糙，GPT的用途相对较小，不会比google更有优势。

而这些数据对于国家、公司、或个人都有隐私性问题，因此必然会被各种限制。因此不论openai和其他公司的技术代差有多大，在相当长时间内都不会像google曾经做到的那样成为全球“大脑”。 而LLM技术本身并没有绝对壁垒，加上llama等开源项目的搅局，因此这个领域会形成“群雄割据”，盘根错节的局面。 蛋糕不会赢家通吃。

2. 大模型终将普及

AI模型有一个本质特征是“黑箱”，也就说说除了数据积累和硬件资源之外，AI领导者似乎并不掌握什么“exclusive formula”。同时，AI模型的商业化本身要求其API是开放的，而API的输出，本身可以被其他从业者用来作为“二次数据”（除非引入某种端到端的加密机制，目前似乎没有任何可操作方案），而利用这些二次数据基本可以复刻出原始的AI模型，因此除了硬件资源壁垒，大模型普及似乎是一个必然的趋势。


3. 什么是prompt engineering 

一直以来，总觉得prompt enginnering 是一个技术迭代过程中的伪命题。 但昨天似乎突然 get 到 prompt enginnering 的真正含义。 如果我们将 GPT 类LLM理解成一种原始的能源，那么prompt enginnering 可以广义理解成：建立能源和用户目标之间的转换关系，类似于马达将电能转换成风能，用来完成消暑的用户目标。

在AIGC背景下，就是建立生成的Context（文本中是模板，图像中是Inpaint 或Controlnet），不论是问答、图片、音频、视频、我们应用AI的本质方式就是建立这种Context。 因此从这种广义概念来理解，prompt engineering 很可能确实是未来的工作方式。

这是一个小小的认知突破。

4. AI纠错码

AI生成存在事实性错误问题，这确实是一个严重风险因素。 但如果我们乐观看待事物，可以如此考虑问题： 计算机芯片的运算也是会出错的，但由于纠错码的存在，我们在实用中，几乎对机器运算的错误可能性完全没有感知。因此AI也许在其自身技术体系中也可以加入纠错机制。

AI和人类智能比，当然有很多劣势，但大模型却有个巨大的优势，就是所有信息是融通的，而人类每个个体的思维能力是无法共享的，由于思维无法共享，导致知识的流通和运用对于人类来说是代价高昂的。每一个人类婴儿诞生，在知识层面上都要归零重启。而GPT让知识实现了一次史无前例的融合，因此虽然AI不一定能生产第一性原理的知识，但也爆发出了巨大的能量，这如同地球上石油储备一样，虽然石油不一定可再生，都由于亿万年的存量储备，让现代工业有了坚实的基础。 而人类历史的知识储备，也为这次信息革命提供了坚实的基础。




