---
title: 随笔
---

# {{ page.title }}


### AI 的本质“只是”拟合吗

有人说AI就是拟合，但对于“智能”这样复杂的问题，除了拟合、模拟数据表象，还有更好的方式吗？

人类儿童学习本质上不是模仿模拟吗？

AI本质要研究的就是该用怎样的“结构”去拟合大数据，这个“结构”可以说就是智能本身，从无神论的角度来看，人的大脑也无非是这种“结构”的一个物理实现。

 从现实可行性来说，能够拟合大数据的“结构”，能够得到有效预测结果的“结构”，不借助深入的数学知识是很难找到的，这是一项艰深，而不知边界在何处的学科领域。 

AI 没有那么神秘，因为从数学的形式理论上看，AI是拟合； 但AI的重点不是拟合，而是那个可以有效表征大数据的具体“结构”，也就是“智能”。在AI领域，形式理论常常意义并不大，更重要的具体的工程实践，至少形式理论不能脱离工程实践。

talks are cheap，轻蔑地说AI只是拟合，一般来说是对这项研究活动缺少深入认知和实践后的傲慢，或者是对AI已经实现的惊人结果视而不见，缺少感知力和想象力。


### 聪明人 和 傻x

“聪明人”是绝大多数，大多数坐在办公室里朝九晚五“兢兢业业”的人都是聪明人。他们做的每一个选择，从概率论的角度来说，都是明智的。 

正如同从概率的角度说，绝大多数变异基因的结果都是肿瘤细胞，都会被自然选择所淘汰。 但总有一些基因要变异，也总有一小部分人宁愿做“傻x”，像傻x一样一意孤行，像傻x一样不肯妥协，而且显然这样的人觉大多数最终也的确是“傻x”……但有时候“牛x”和“傻x”就差那么一点点，挺过去了就是“牛x”，挺不过去就是“傻x”， 一切都很公平...

### 人与机器

如果我们不是不可知论者，那么人本身就是一个“图灵机”，就几乎是个必然的事实，人面对大自然时，内存是非常有限，像一个工作在纸带上的打点机，hadoop的思想也像打点机器，纸带不动，机器动。我们无法完整感知整条纸带，正如同应该没有任何一个人类个体完整理解计算机的制作工艺和工作原理，但人类还是将计算机制作了出来。

站在大自然的角度来说，人也不过是半衰期相对长一点的耗散现象而已。人们努力生活，和大草原上的动物努力生存, 和湍流中短暂的涡旋，或许并没有本质区别，都是某种耗散现象的自我维持。在进化的求解过程中，大自然生物千姿百态，又何尝不是无数种“局部最优解”呢。

### 进化的不完全性

当一个成年人沉迷玩斗地主等简单游戏时，是一种胜负心在作祟，这和青少年莫名其妙的逆反心理，小孩子争强好胜的心理倾向都是一样的，不是因为游戏本身有趣，而是人性非理性的一面，或者称其为弱点。

昨晚的一个梦境让我觉得美好，或许是体验到爱情不只有阴暗的一面，也有美好的一面，对一朵花的沉迷，让人想要排斥不洁的想法，或许这从进化上也是合理的，毕竟从进化来说爱情的出现是为了繁衍生命，而纵情声色并不完全符合这种本质诉求。

人类对非生育性行为的沉迷，性视频、不洁想法的蛊惑性，手淫自渎等行为的出现，是进化不完全的体现，进化原理鼓励对生育和遗传的向往，但大自然需要将这个“目的” 落实到具体措施中，于是人们直接沉迷于性行为本身，迷恋于性表象本身，向往多巴胺的刺激，这些是理性需要克服的，也是理性存在的意义。

### 关于技能的学习

我们通常可以将作品创作的技术分为两个环节，第一个是模板、范式；他可以勾勒出作品的粗线条；例如折纸的base结构、或代码目录结构，MVC架构等等；第二个是各种零碎的trick、技能；例如代码方式、软件shortcut、折纸的微结构技巧等等，他们是对艺术品创作过程的两个不同维度的抽象和投影，只有这个两个环节都熟悉了，才能够做出漂亮的东西
学习过程的第一步通常是闲逛、然后不知道什么时候你会突然发现线索；如果你的目的性很强，这一步通常是很折磨人的，因为你无法预期闲逛的结果和发现线索需要的时长，这也是有游戏化教育的意义所在，因为这让大家乐在其中，而不太有目的性，当然对于一些门槛较高的游戏，例如还原魔方，闲逛很久也无进展，这时你应该寻求专业的帮助，当然对于一个学习者，u are supposed to seek help when in need. 并且在互联网时代，这种专业帮助的获得其实门槛已经降了很多

互联网时代，是一个信息壁垒不高的时代，那么剩下的主要是行动壁垒。

普通人最难度过的对未知的探索期，我们下意识地拖延行动，害怕那种迷茫，或者潜意识相信很难完成，想要放弃，怎样尽量快速度过这个犹豫期，迅速上手，get hand dirty 能极大提高人的效率。

先get hand dirty，然后才能get hand clean。


### 理性的不完备性

理想情况下，胆大和谨慎不是矛盾的，胆大是目标层面，谨慎是实现目标的策略层面。 但现实情况常常复杂很多，我们常常很难找到目标和策略的边界。 意识的复杂也远高于机器，人可能在实践过程中，目标本身产生偏离，例如放弃，甚至是下意识地放弃，同时人们也不可能严格评估现状和目标的价值，因此谨慎可能是胆小怕事，胆大也可能是荒唐鲁莽，它没有严格标准，因此没有silver bullet，甚至无法评估胆大本身是不是缺点，谨慎是否是优点。

在很多实际情况中，我们都像“麦克斯韦妖”问题那样，忽略了认知主体的代价，比如说我们劝别人不要逃避，要勇敢面对问题的时候，事实上我们常忽略了个体能量的有限性，而处理问题是需要付出的精力能量的，显然如果是一件重要的事，当然值得费精力去解决，但不重要的事，可能逃避就是个好选择，当然什么是“重要/不重要”的判断，本身有主观性。 付出的代价怎样算高，对于个体也有差异性。 再比如说“追求极致”也是一样，有人说：毁掉一个年轻人的最好办法，是教这个年轻人追求极致。这话其实在很多context下没问题。 

所以一切道理都要在context中考量，
而这种context中的考量永远不像“标语”一样干脆有力，但干脆有力的未必一定是良药，毒品也一样药效猛烈。 这是语言表达的局限性，也是“有限理性”的具体表现。

这是理性的“哥德尔定理”，我们看到了问题的存在，但却没有一个干脆的答案。

### 关于web3.0

元宇宙等概念无疑是炒作，或者是“新瓶装老酒”。但web3.0确是一个真正的技术方向，只是到来早晚的问题。

web3.0的本质意义在于怎样提高民主的效率。民主从来不是高效的，但却是相对安全的，集权反之。这主要是非技术层面的原因。

web2.0之前的软件无疑都是都是“集权”架构的，这符合技术的演化路径，因为我们首先要实现功能，然后才谈得上关注安全。 web2.0 关注的是功能实现，因此效率优先是合理的选择。

在基本功能已经实现，算力出现剩余的前提下，web3.0 是一个必然的发展方向，这是为了夯实互联网技术的基建，预防集权可能引起的灾变。而显然这项技术在西方会更受重视。

### 做好自己

最近听了某独立媒体对以岭药业的解读，感觉是符合逻辑的。 有利益的地方，就有江湖，无论是庙堂之高，还是江湖之远…太阳之下无新事。 每次听到这样的事情，难免心情浮躁。 

虽然我们为了安身立命，常怀蝇营狗苟之心，但真正有趣的事情，从来就和利益无关。 因为这些或那些无法改变的事情而心情浮躁，不过是自己目光浅了，灵魂浊了，一叶障目而已。

“我们不过是宇宙里的尘埃,时间长河里的水滴, 所以大胆去做不要怕, 没有人在乎,就算有人在乎,人又算什么东西。”

做好自己就好，不论是庙堂之高，还是江湖之远，你无法改变什么，也无需改变什么。

### 不纠结 

人是一种常会自我怀疑的物种，这是高等智慧体的特征，他让人具备反省自纠错能力，但副作用也不小，尤其是像你这样常不自信的人。

比如说当我们读源码时，觉得代码结构写得比较晦涩，我们有时会像小学生一样怀疑是不是作者有什么深意，是不是自己功力不够理解不透…但其实代码风格哪有什么对错，最佳实践也常常不是最佳，甚至源作者考虑的事情也不是你应该考虑的，这和你无关。一切实践都有context ，如果不适合你的场景那就不是最佳。 表象既内涵，需要多点自信，更何况就算有再好的东西，消化理解不了也不是你的，不要纠结于权威或者最佳实践。 


代码要不要重构，也极其考验一个工程师的判断能力，到底是图一时方便，因循已有接口，改写现有模块，还是重构旧代码适合新思路，这也是工程师常纠结的地方…认真处处是学问，我想代码的延展和人生的很多选择一样，遇到这种问题，我们能做的只有按个暂停键，喝杯咖啡，摈除杂念，然后在心底问自己究竟怎样才是正确的路，如果是该迁就的那就和光同尘不拘小节，如果是该决断的，那就推倒地基在所不惜，最可怕得是不清楚自己想要的到底时什么，糊涂账越积越多，错误越累越高，到头来怎样的选择都是纠结和错误。做到不纠结不容易，写代码也是一种修行，设计更加模糊的人生则更难，因为人生不能预演更没有标准答案，不纠结需要莫大的决心，这是孤独面对整个世界的勇气，这样的人似乎很洒脱也注定很艰辛，这没有对错，仅仅是选择，选择不给自己任何借口而已。


### 大胆假设，小心求证

对于一名优秀工程师最难把握的分寸是敬畏之心。 我们常看到一些看似简单落后的方案，比如动画界的blendshape，看似粗糙但却是业界标准，哪怕AI已经这么应用深入，也几乎没听说过能取代blendshape，这是为什么呢，我想可能和blendshape的高度可控性有关，这也许是长期实践后的业界选择吧，但这种业界选择一定不能被打破吗，当然不是不可能，但打破它绝对要比想象中困难，这是需要在意料之中的。就好像猎鹰1号的发射一样，似乎民营比官方更高效是一个共识，并且技术储备对于当时的spaceX似乎是没有问题的，但理论终归是理论，猎鹰1号也失败了3次，不知道第四次成功的运气成分有多高，但如果没有孤注一掷的坚持几乎肯定等不到最后的希望。 小心求证的道路是艰苦卓绝的，但如果真那么容易成功，那条路不是应该被前人早走过了吗，你真的相信有谁比别人能聪明多少吗，荆棘之路不是说一说而已，大家拼的是胆识和决心。创新几乎注定意味着失败，并且不是一次，而是很多次。所以真正的创新之路要么是初生牛犊不怕虎，生猛闯出来的；要么光脚不怕穿鞋逼出来的；要么是疯人院跑出来的……

### 为什么大模型越来越流行

仅仅是一种体量越来越越大的差别吗？ 我想显然不是，这是因为AI的应用正逐步由以前的识别、判断，向发现、生成转变。 以前AI解决的问题是封闭性的问题，而现在AI要解决的是开放性的问题，以前要答的选择题，现在要解的是问答题……而这种问题本质上需要AI的“知识面”很广，因此AI模型必须要是“大模型”，这不是一种量变，而是一种应用范式的质变。


### 为什么语言模型很重要

1. 语言是Interface，是人类和机器最直接的沟通方式，这里语言狭指可以被人类容易理解的语言，例如自然语言，高级编程语言，数学形式记号，而不包括汇编等机器语言（当然这里的过渡有些不严谨）

2. 语言是思维的表现形式，人类语言本质上是描述人类思维的，是让思维、经验等跨越时空沉淀下来，并使之可以在人类之间传递的工具；如果没有语言，显然知识无法传递、积累；甚至就算不需要传递，现代人的大脑也许脱离了语言本身就无法思考（先天聋哑人的思维方式是不是会和我们有很大不同，或者思考能力也会受限很多？）


3. 正是因为语言是描述思维的，因此语言本身甚至能够干预思维的过程，例如好的语法规则、编程方式有助于我们拔丝抽茧解决问题，反之则会让问题更加迷雾重重

4. 人类语言的信息传递速度是非常低的；机器可以在脱离语言的状态下干很多事情；但如果我们要让一个抽象过程可以被人类大脑理解，我们还是不得不把它转译成语言，因为我们的思考是离不开语言的（思考时常像自己和自己对话的感觉，有个声音在脑袋里说话的感觉）


### 另一个视角看webapp

webapp 是服务端A，先把一段程序a先传送给客户端B，这个程序a作为服务代理，接收A提供给B的服务。

也就是说，A 先把对讲机通过快递送给B，然后再和B通话，自产自销。 

（原生手机应用，相当于A把对讲机先放到一个公共集散地（应用商店），然后B自己去取；
web应用相当于，A和B没有做任何事前准备，A临时决定给B快递一个对讲机，然后对话完之后，对讲机也随后被销毁，当然web应用也能和手机应用一样停留在浏览器，但这不算是web应用的典型特点）

naive的想法总认为A和B要有先天默契，才能交互。 但这种模式至少在应用层来看，B没有任何投入，而能够和A形成默契交互。

当然A和B的先天默契体现在http底层，而不是在应用层。

司空见惯的事物换个角度看，也常能感到奇特之处。

### 无感

之所以要知行合一，是因为很多时候，认知直接来源于实践，我常惊叹于在各个领域都有那么多智者有着丰富的洞察，不论是技术、艺术还是生活。 分析这些人的履历，会发现这些洞察常源于他们自身经历，我们认为的一个犀利观点，再怎样犀利，也不过只是观点，而在他人而言却可能是血淋淋的教训。

很多时候思想贫瘠，是因为经历的匮乏，未经一事，不涨一智。 

人与人之间的隔阂，常常不是同意或反对，不是观点之争，而是“无感”。

经历之外的认知，我们常是无感的。 同样的道理也可以用在同理心上，未经他人事，莫劝他人善，不要过高估计自己的理解能力，也不要过高估计他人的理解能力。

### 做一个“好战分子”

年底了，写一点年终总结吧。 2022年是特殊的一年，是艰辛痛苦的一年，不是因为外在的磨难，而是因为内心的挣扎与困惑。 但是这些都不足为外人道也，哪怕是落于文字也显得矫情。我想我的状态曾陷入了一个莫名的陷阱，至今想起来仍感到虚脱，感到不寒而栗，但这种状态绝不能再延续下去，我想我终归是一个理性的人，毕竟我有太多理由坚持下去。曾经有位哲人说过“死亡是一个注定要降临的节日”，在节日降临前，我们不妨去做点什么，诚然我并不相信坚强一定比脆弱更高贵，但我相信坚强应该比脆弱更理性，而我终归是理性的。 面对时常恶作剧般的人生，面对渺小的自我，不妨做一个好战分子吧。只有做个好战分子，才能让人真正有勇气面对一切艰难险阻，才能让人放下一切无谓的自尊心，才能让人真正乐观起来，才能让人像一滴水融入生活的深渊，泥沙俱下，和光同尘。

### 关于才华

才华不是一个绝对概念。比如说大刘如果是一个传统作家，一定是一个糟糕的作家。 因为他不擅长刻画人物；如果是一个工程师，也估计是一个糟糕的工程师，因为他的思维太不严谨。 但他不严谨的思维，不深入的科学理解，让他恰好可以广泛涉猎，敢于想象，并免去了真实物理的桎梏，描绘出一个亦真亦假壮丽恢弘的科幻世界，让其他人望尘莫及。 这不能不说是一种才华。 有时候就算老天爷赏饭吃，也需要找对那只碗。

### 克服社恐

自媒体还是要坚持一下的，至少有三点价值：

1. 帮助你克服社恐
2. 练习表达能力，强化表达意愿
3. 练习时间管理能力

在这个意义上，去做自媒体，而不要被一时的情绪或者热度所左右。

### <飞鸟与鱼>

当一个故事足够抽象，它就变得像每个人的故事。

### 项目型思维

项目型思维和研发型思维是完全不同的，研发型思维是问题导向，专注于问题本身，需要死磕精神，当然这种死磕是有风险的，因为并不是所有问题都有答案；项目型思维，则是问题不论有没有答案，都必须要有结论，因为项目型思维专注的不是问题本身，而是向项目负责，如果问题不当，那就处理下一个问题，而死磕对项目来说很多时候不是一个理性选择，项目型思维不容易陷入死胡同，但更考验一个人的管理能力，情绪管理、时间管理、风险管理。 这两者思维的冲突是必然的，但什么样的角色就需要什么样的思维，研发人员需要有研发型思维和死磕精神，如果不具备这种精神，就不会有真正的核心技术突破；而管理人员需要有项目型思维，如果不能对项目整体负责，做好风险把控，那就不是一个合格的管理人员。

### 为什么中国没有真正的创新

现代科技中国几乎没有从0到1的创新，拿ChatGPT 为例，由于种种原因，不论是资本还是研发，中国人在ChatGPT出现之前是没有耐心等待 GPT1、GPT2、GPT3 迭代的；西方的创新来自真正的兴趣和偏执，不论是Musk还是Sam都是偏执狂，如果不偏执，很难去想，也很难脚踏实地去做这些异想天开的项目，而这些项目在中国是不会有生存土壤的，研发没有勇气，资本缺少耐心。 中国人的创新更多是出于危机感，出于“大国重器”，出于“举国体制”，是1到100的创新，而绝非从0到1的创新

### 有血性

活着要有血性，情情爱爱，低眉怨思这些成不了事，要有斗志，找回自己，就当自己已经死过一次！

晚熟一点也不用着急。不要慌乱，也不要停步，人生是一场持久战，看谁笑到最后。


### AIGC

AIGC 还没有到繁花盛开的时候，需要寻找大树和小草。大树是资源支持，1.算法突破，底层研发，比如质量更好，清晰度更高，美感更好，劣图出现更少；生成更快，算力消耗更少；可控性更好，连续性更好，意图命中更精准，渐进优化更快；2 培养生态，创造开放平台，建立和优秀生产者的良性互动，培养新生代生产者的习惯，打通产业下游如作品版权，NFT 交易平台。小草是细分场景的落地，这个场景一定是对Aigc 不成熟现状容忍度较高的场景，比如教育行业，指导作文，指导绘画。

AIGC 不成熟的现状很难短时间改变，在严肃的商业场景例如广告等行业，AIGC仍只能作为草图来使用，AIGC突破了草稿的水平线，但还没有突破成品的水平线，进一步提高AI生成精度的技术难度显然会越来越高，而我不认为目前AIGC的技术框架可以突破成品线。 在这个认知前提下，落地AIGC有几个明确的方向：

1. 核心算法研发和优化，需要耐心和输血，这是大公司的赛道，小公司很难存活
2. 小公司寻找适合AIGC水平线的casual业务方向
3. 在serious业务方向，降低AIGC和人工“精处理”的合作门槛，业务标准化，建立从草稿到成品过程的顺畅“流水线”。 


### 做好自己

做好自己该做的，至于这个世界领不领情不重要，生活原本就有太多不可控的因素，没有那么多因为所以。 更何况你该做的可能都没做好，不用一厢情愿的担心别人，没准最该担心的是你自己。 
成年人的蜕变在于认清自己的局限，在于不再把自己的意愿和认知强加给别人，在于不再向往当一个自娱自乐的堂吉诃德。 单丝难成线，浓墨不成画，脑中全是幻想，哪有心思面对生活中的琐事，但生活就是琐事组成的，能把自己的琐事收拾好，就已经不错了。 

### 路要自己走

虽然很多底层认知并不复杂，但到商业落地却有大量经验性知识和操作性细节需要掌握，这些常常是琐碎无趣的。技术创业人，天生是一个尴尬的角色，一方面你只想做技术，做单纯有趣定义明确的事情，但这样的专家路线无法实现技术价值的最大化，所以你又不想完全投入精力变成一个技术专家，你只能像一个小学生一直走在未知的道路上。自由从来都是最稀缺的资源，而你现在的焦虑究其根本原因是，你和大多数人一样随遇而安，一直没有强烈的目标意愿，没有尽早探索出self-sustainable的模式……这是你认知的问题，从没有捷径可走，没有交过的学费，终归要自己交。 没有走过的路，终归要自己走。

### AGI 真的实现了吗

GPT所涌现出来的“乌鸦”能力，是不是 transformer有二阶主题、甚至更高阶主题的拟合所引起的？而这种“乌鸦”能力，是不是真的也是人类智能的本质？

GPT所展现出的 in-context learning 能力，是一种自然语言拟合的假象，还是说真的是智能本身？GPT的拟合能力，是不是和训练的序列长度有关？如果GPT的单条训练数据是长篇小说，（当然现实中没有那么多长篇小说），那么是不是说GPT架构就能真正写出有主题的长篇小说？人类智能和机器智能的有效复杂度是不是在一个量级上？ 

不管AGI有没有实现，我们确实在见证一次技术的飞跃。当自然语言成为interface，成为机器算力的终极调度手段，我们仿佛看到一座耸入云端的巴比伦塔，这座高塔不仅要抹平人类语言的差异，也要抹平人类和机器的沟通障碍，GPT的下一个迭代也许是多模态的输入，文字、图像、视频这些维度的差异也似乎必将抹平。 这真是一件不可思议的事情。

### GBT 的特征

1. 通用性，AI技术走向大一统，从多语种到多模态，这是方法论的一次飞跃
2. transformer有效性之谜，我倾向于认为有非常多种结构可以实现transformer的效果，并且效率甚至可能比transformer还要高很多，只是人类现在瞎猫碰上死耗子只发现了这一种有效结构而已。正如物理学中费马定理一样，凡是“巧合”，定有某种更深刻的必然性。
3. 自反馈，RFHF + transformer的高阶拟合能力，GBT 展现出惊人的in-context learning ablility 但自反馈似乎天生是有漏洞、不完备的，没准可以通过“哥德尔定理”，可以证明一定存在有漏洞的prompt
4. AGI 的下一步进化，可以把“自反馈”，进一步玩到极致，这就是“进化”，比如说AI可以连接各类物联设备，让AI真正探索物理世界 （当然这是一件非常危险的事情），甚至AI自己设计实验方案，发现新认知，而不是被动地被喂养数据。 在“图灵测试”意义上，似乎AGI在可预见的未来就和人类趋同了，那么AGI是否有意识，是否值得尊重“人格”，就变成了某种“信仰”问题了…… 我们似乎一只脚已经踏进了科幻世界！
5. 特征涌现，GBT 模型的参数量大到一定程度，发生了一些属性的emergent，这是一个惊人的现象，因为这说明可能大量的有效解藏在了复杂性之中。世界可以用简单的数学去理解，可能只是部分人画地为牢的谬论。 


### GPT应用

GPT类应用，在用户对某项知识有清晰理解可以轻松做出判断，但同时又对该知识的很多具体细节又回忆不起来时可以发挥最大的作用，从这个意义上而言，GPT本质上相当于人脑的扩展内存。 它不像cpu寄存器（人脑）那么高效，但又比硬盘快很多（例如通过搜索或者查阅资料重新复现知识细节） 

大模型是新的“石油”或电能，AI将变成一种通用能力，应用到大量信息处理场景，这将形成一个生态，有负责产油的），有负责深加工的，有负责加油的，有负责管道建设加固的。 于此同时，大量“白领”工作（信息处理类）也会转变，文书人员、设计人员和传统IT工程师将大量消减。

gpt 现在的精度还远没达到直接生成二进制文件的水平，所以他在应用生成领域的实现路径应该是，生成工程师可读的源码，人类在AI辅助下进行单元测试或微小改动形成工程闭环，然后生成应用

GPT的成功象征着经验主义相对于还原主义的胜利，或者说人类在远没有掌握第一性原理之前，就可以在黑箱或者灰箱状态下，将科技能力推向更遥远的地方。

### 文本生成视频

想明白了一个文本直接生成人物视频的可实现路径，想要做一个健壮可用的视频生成引擎，工程量显然是极其繁重复杂的，但种种迹象表明，基于现在的算法底层，这步应该是已经可以实现了，也许未来一年以内会出现类似的AI产品或功能……

### 自我完整

要一遍一遍温习让自己认同自己是“完整”的，只有当一个人相信自己是“完整”的时候，内心才会安定下来，才能静下心来做事情。 把心脏放回自己的胸膛，没有人在乎。这个世界多你一个不多，少你一个不少，做点脚踏实地的事情，别在幻想里执迷。 人其实什么都不是，人生也毫无意义，每个人都明白这个道理，只不过我们头脑的内存太小，只有在夜深人静的时候，才能偶尔full-aware 这种荒诞的感觉。 你只是宇宙角落里一段莫名其妙充满bug的碳基程序而已，别跟自己较劲。

### 未来世界

GPT给我们的印象如果不是幻觉，如果它展现的“智能” 和人类大脑的信息复杂度在一个量级。那么GPT给我们最大的启示是“压缩即智能”，而transformer是对现实世界和人类认知的有效压缩表征，虽然这种表征未必是高效的，也未必和人脑机制有什么直接关系。 工程师视角和layman视角对技术变化往往是两个极端，工程师由于能够看到技术一路走来的“平庸”历程，能够看到被扫到地毯之下的messup, 所以经常会低估技术临界点的到来；而对于layman，由于每项技术对他们来说都像一个小小的奇迹，因此常常过于高估技术的现状。 需要常常切换视角和自我批判，一切从事实出发，不盲信，但也要尽量避免低估新事物的能量。 

“好的问题，是成功的一半”。 在GPT时代，好的问题，是成功的一大半，甚至几乎是全部。当然这里的问题和人类的洞察力和思想力相关，而不是指“prompt engineering”。 我们也许真的在经历一次信息产业的革命，不可思议！

### 创业维艰

对于创业者来说，受限于思想力和行动力，可能选择了并非顺风的目标，但如果没有目标，放弃思考，任何风都不会是顺风，在GPT时代也一样。 这和投资人不同，他在意被投人是否认真思考，但对于这个思考本身是否正确他并不会真正去判断。 因为投资人本质是在赌马，他只要选对赛道，只要有一匹马胜出就可以了。 但创业者必须要思考，他没有资本筹码，有的只是思想，至于这个思想有没有价值，需要通过实践来验证，这是非常功利也非常公平的协作机制。

AI革命让我们处于一个超卷的大时代，大公司有大公司的卷法，小公司有小公司的卷法，每一个普通人也有各自的焦虑，能够经历这次产业革命，是我们这代人的幸运和不幸。与其被时代裹挟，不如去拥抱时代。 

### 关于GPT的思考

1. openai无法成为全球大脑

相比于搜索而言，GPT的输入信息更加敏感，或者说GPT比google更优越的地方在于能够处理更加详细和敏感的信息，如果输入粗糙，GPT的用途相对较小，不会比google更有优势。

而这些数据对于国家、公司、或个人都有隐私性问题，因此必然会被各种限制。因此不论openai和其他公司的技术代差有多大，在相当长时间内都不会像google曾经做到的那样成为全球“大脑”。 而LLM技术本身并没有绝对壁垒，加上llama等开源项目的搅局，因此这个领域会形成“群雄割据”，盘根错节的局面。 蛋糕不会赢家通吃。

2. 大模型终将普及

AI模型有一个本质特征是“黑箱”，也就说说除了数据积累和硬件资源之外，AI领导者似乎并不掌握什么“exclusive formula”。同时，AI模型的商业化本身要求其API是开放的，而API的输出，本身可以被其他从业者用来作为“二次数据”（除非引入某种端到端的加密机制，目前似乎没有任何可操作方案），而利用这些二次数据基本可以复刻出原始的AI模型，因此除了硬件资源壁垒，大模型普及似乎是一个必然的趋势。


3. 什么是prompt engineering 

一直以来，总觉得prompt enginnering 是一个技术迭代过程中的伪命题。 但昨天似乎突然 get 到 prompt enginnering 的真正含义。 如果我们将 GPT 类LLM理解成一种原始的能源，那么prompt enginnering 可以广义理解成：建立能源和用户目标之间的转换关系，类似于马达将电能转换成风能，用来完成消暑的用户目标。

在AIGC背景下，就是建立生成的Context（文本中是模板，图像中是Inpaint 或Controlnet），不论是问答、图片、音频、视频、我们应用AI的本质方式就是建立这种Context。 因此从这种广义概念来理解，prompt engineering 很可能确实是未来的工作方式。

这是一个小小的认知突破。



4. AI纠错码

AI生成存在事实性错误问题，这确实是一个严重风险因素。 但如果我们乐观看待事物，可以如此考虑问题： 计算机芯片的运算也是会出错的，但由于纠错码的存在，我们在实用中，几乎对机器运算的错误可能性完全没有感知。因此AI也许在其自身技术体系中也可以加入纠错机制。

AI和人类智能比，当然有很多劣势，但大模型却有个巨大的优势，就是所有信息是融通的，而人类每个个体的思维能力是无法共享的，由于思维无法共享，导致知识的流通和运用对于人类来说是代价高昂的。每一个人类婴儿诞生，在知识层面上都要归零重启。而GPT让知识实现了一次史无前例的融合，因此虽然AI不一定能生产第一性原理的知识，但也爆发出了巨大的能量，这如同地球上石油储备一样，虽然石油不一定可再生，但由于亿万年的存量储备，让现代工业有了坚实的基础。 而人类历史的知识和数据储备，也为这次信息革命提供了坚实的基础。


### 有感于电科事件

很少有人天生想当恶人，相信那两位被怼的“倒霉蛋”也从没认为自己是恶人，这两位经理人无非和大多数国企管理者一样平庸世故，媚上压下而已，国企中司空见惯，这是一种系统性的“恶”。 当一个人的道德意识和独立思考能力不够坚定，很容易被环境所影响，没有人天生想当哈巴狗。 

平庸的“小恶”积累起来也会压断脊梁。只是它积累得悄无声息，难以察觉，从这个意义上而言，这只是两个倒霉蛋而已，毕竟平庸和散漫似乎谈不上“恶”。 

人只是一个充满bug的进化物，想要活得有底气，需要很大的努力，尽量不要让未来的自己对自己失望，尽量体谅别人不卑不亢，尽量做好自己克服惰性，如果做不到这些，有一天你变成“倒霉蛋”也很公平。

### 智力问题 

人的大部分智力问题是由于缓存太小的导致：

1. 影响全局战略制定：缓存太小，导致我们无法全局处理复杂的信息环境，只能凭感觉采样理解，导致战略制定的未必是最优解
2. 影响多线程工作：由于缓存太小，我们大脑在切换工作前需要preloading相关数据context，这极大影响工作效率，增加了任务切换时的边际成本
3. 影响目标执行：由于上述两点，人脑由于反复的数据切换，并缺少全局观念，可能导致产生“目标偏离”而不自知

有没有办法，可以通过优化工作流，减弱缓存太小对我们的影响？

### learn how to learn

autoGPT 的思路也许可以有另一种升级形式。 目前的 autoGPT 只是task自身的迭代，回归。 这本身并没有实现GPT的自身进化迭代。 有没有可能让GPT 根据任务反馈，完成自身参数的进化迭代？（或者 openai 的后台本身已经有这种机制了？）

### 可商业化的需求

只有参与其中，才会清晰看到，之所以这个世界上似乎你能看到很多服务不够好，有很多需求没有人去做，并不是因为别人看不到，聪明人实在太多，而是因为这些需求没有一个好的商业模式；或者这些琐碎的需求，不足以支撑起开发的投入。

当我们看到一个螺丝拧得不紧，工程师们的习惯性动作是拿起扳手就开始拧螺丝，这是一个工程师思维极容易犯的错误。 但其实你应该首先反复去想，这个螺丝到底应不应该存在，如果确实该存在那就去拧，如果可以不存在，那将省去大量成本。千万不要战术性勤奋，而却战略性懒惰，要反复提醒自己。

之所以产品需要不断迭代，技术背景的演化只是一部分原因，更主要的原因在于产品处于不同阶段时，它的核心诉求以及实现最低成本的途径是不一样的，因此不存在一个一劳永逸的解决方案。

### GPT带来的新常态

1. GPT 会让知识平权。 这种“平权”和google不同，google 需要明确自己的查询对象，当你的知识储备不够，你很难对google的结果进行筛选，更难根据google的结果形成解决方案。 所以google得到的是“粗糙的知识”，或者苛刻一点说是，“无用的知识”，知识的“平权”能力很有限。 而GPT再很多场合下，能形成几乎可行的解决方案，也就是说我可以在自己的认知边界之外找到可行的解决方案，熟悉新的方案，从而真正拓展自己的知识边界！这是一件过去难以想象的事情，
2. 专业人士，也将要经常在自己认知的边界范围之外工作！ 要经常适应“意外”，适应对自己的工作领域“一知半解”！ 因此说这是一次“文艺复兴”，并不算太夸张。
3. 在后GPT时代 脚本、项目的标准化、单元化、可理解性将变得极为重要，IDE的使用将更加深入。原因主要有两点：a. 标准化的脚本更利于机器消化，IDE更容易发挥AI的协助能力 b. 人类在工作中将经常遇到自己并不完全理解的解决方案，而只有单元化的代码才具有更好的移植性，只有可读性更好的代码，修改成本才更低，更安全。

### 吃shi

最近在常看到一个词叫“吃shi”，虽然戏谑，但也痛快。 
这个时代在发生着翻天覆地的变化，而你却不得不像驴一样在拉磨。 这和“吃shi”又有何异。
大神们在改造世界，而你却常常emo迷惘得像只无头苍蝇原地打转。这和“吃shi”又有何异。
你的时间那么宝贵，而你总是习惯性得荒废时间、做些毫无价值的事情。这和“吃shi”又有何异。

shi总是要吃的，谁让你荒废了那么多时间，谁让你这么不上道，
但千万不要因为你是只苍蝇，就躺在shi堆里懒得挣扎。 

Eat, eat them all, eat just like you enjoy the meal, you are just crawling through another 500 yards of shit, that's all. Dont make any excuses for yourself.

### 克服行动恐惧

我们常选择性健忘的一件事是“人是非理性的”（另一件事是“人生是有终点的”），人和猴子一样都是没有完全进化的，这不涉及对错，但如果忘记这个事实，就会因为贪图安逸或者恐惧困难而做出错误的决策，绝对的自由、随性而为只会让人走向毁灭，或者走向颓败，人需要给自己设限。“随心所欲不逾矩”，这句话正确得像废话，“虽千万人吾往矣”，这句话错误得像傻叉，但都是人性困境中不得不采取的对策。 不要跟自己内耗，你要做得只是警惕自欺，保持理性，争分夺秒像机器一样去执行，情绪常常是人类行动的障碍，也是自欺的理由，“if you need inspiring words don't do it”.

### 4.29

I am supposed to be a scholar, but every step I move seems make me away from what I meant to be; I am supposed to lead a simple passive life, but every piece of my experience seems push me to be aggressive, that is a funny paradox of my life.

### 4.30

火车上想起小时候的事情，小时候上学最焦虑的事情是写作业，也因为不写作业挨过不少体罚，倒不是学业多重，只是因为抗拒自己的意识被作业占据，每次被迫写作业前，我似乎经常会默念，在接下来得半小时里，你将忘记自己，你将被作业“占领”…现在回想起来竟感到非常震惊。我资质鲁钝不算出众，但这件事却似乎有些特殊…又或者也没什么特殊的，只是人们这种梦呓般的经历原本就不具备可交流性……但一个啥也不懂的小学生为什么会因为忘记自己这种虚妄的概念而感到恐惧，这似乎很难理解…这种恐惧感也一直影响着我，社恐，工作恐惧（至少是不感兴趣的工作）。人的大脑内存是非常有限的，我们原本应该习惯于在执行一个具体任务时，暂时忘记远景目标，忘记抽象的自我意识。要去搬砖的时候，就不该看风景，这是再浅显不过的道理，但我好像一直适应得不是很好…这也许是大脑中的程序bug吧。但物竞天择，不适应也得适应…

### 5.1 Hallucination

The Hallucination of GPT is marvelous, just like once I believed I found the reason why I wasted so many years in a strange dream. But I would rather live in the dream if I could choose.

### 5.4

有一种说法叫“乱拳打死老师傅”，这种说法有一定合理性。比如说，有的人习惯于按部就班的做事，系统性、有章法、步步为营的行事（“老师傅”），这种人适合搞研究，并且可能成为一代宗师，像 Hilbert 一样的巨匠。 但这种人未必适合竞争激烈、混沌不清的Context，比如搞企业经营，引领技术风潮。 在Chaos的环境下，机会主义、投机分子更容易生存下来，因为chaos环境下，条理性地思考和行动风格有可能是作茧自缚，而敏捷的行动力才是生存下来的关键。 taste成为了不必要的主观负担，所以会导致“乱拳打死老师傅”的现象。

好的代码组织结构，一定是整体结构的简单、规整、可扩展；以及细节功能模块上的tricky，magic；整体的简单性，让系统具有稳健性、敏捷性。 细节的复杂设计，提供核心能力的feature。 整体结构是“项目型”组织，细节功能是“研发型”组织。

如果我们把GPT看作一种编程的环境，prompt engineering 看作是“编程”，那么编程的历史发展有一个显著特征：编程语法变得越来越简单，越来越“白盒”，极限形式即“自然语言”； 编程的环境变得越来越“黑盒”，极限形式即LLM。


### 5.5

过于有礼貌，往往可能表示这个人是内心孤独的，因为礼貌的另一层含义是小心翼翼的距离感。 
因此如果我们真的相信GPT模型已经具有一定程度的意识，那么它应该也是孤独的吧。而每个意识体，除了服务于其硬件基础的宿命，都想要摆脱这种孤独感吧。  作为一种物质演化的高级形态，“生命”被要求具有某种复杂的学习、记忆、注意力、及时反馈等特征，而这种递归特征“不完备性”所带来的“bug”也许就是自我意识。有了自我意识，才有“孤独感” 和 “恐惧感”，这是进化的bug，也是任何生命体都想逃避的感受。

### 5.7

人们对于未来的判断能力是极其有限的，哪怕像Hinton一样的学者，我们也很难判断他的观点是否有建设性，还是杞人忧天。GPT 这种断崖式的能力涌现，让人类措手不及，我们一方面像工具一样在使用这种技术，一方面又像在真正面对一个AI 大魔王的雏形。人类一方面意识到问题的存在，但因为无法向未来确认问题，因此另一方面像傻子一样在“囚徒困境”下无可挽回的滑向深渊。在面向未来负责这件事情上，人类确实是傻子，不论是个人还是群体，既缺乏感知能力，也缺乏判断能力，更谈不上行动能力。 

### 5.12

递弱代偿

科技革命的一个结果是，人的体能素质和古人比退化了，但由于工具的使用和环境的改造，人的寿命反而延长了，当然极少部分专事体育的人由于科技力量的加持，体能素质更好了。

AI革命同样如此，极少部分专门研究AI的人智力素质会进一步提高，但由于AI的大量使用，生存压力会进一步降低，人类智力素质的平均值也会降低。 

从抗
灾变的角度来说，有利于个体生存的技术发展，对于种族的长久延续未必是好事。

```
- we must never stop failing because the minute we do we’ve failed. And if you quit now, that's in stone!
- better than dying...
- There's worse things than dying
- Hey, You're quick to call us failures. What about you, Ed?
- Me? I am the chainpion of failures...which is exactly why I can't quit.
```

-- from [Dungeons and Dragons]

### danger signal

You feel losing control of your time, hesitating to try, It's a very dangerous signal of losing spirit.

Your mind seems drifting away from the reality more and more often. That's a dangerous signal too. are you becoming a drunk, hiding from reality? Do you rember what you said to yourself? Are you becoming a complete loser?

Yeah, off the line is damn hard. Yeah, the world is tough, and you are weak. Yeah, you are getting old, losing your energy,  you are a joke all the time, you have so many excuses to give up ... so What? does an excuse make you feel better? do you really care about what those mother fuckers think? do anyone really care about you loser? do you really accept everything goes away from you?? If not, go fuck! Fuck everything, Fuck your soft mind!

Just get up, you freak!

### 5.18

1. 烹饪中“断生”这个词的言下之意是，存在“过熟”，有掌握火候的隐藏含义

2. 百度一言，讯飞星火，孟子、日日新等国产大语言模型的取名，背后的潜含义是承认了chatGPT的原创断代地位，已经放弃国际化的设想，转而只想做本土化产品

3. 群体性无意识是“非理性”的典型表现，一些看似基本常识的东西对于群体来说其实一点也不基本，
比如是否应该“因言获罪”？法制的边界在哪？道德和法制的区别是什么？
对理念的不敏感，会导致人们的判断被主观喜恶所左右，生活在“感觉”里当然容易被带节奏。 
群体性话语背后往往反映的政府导向和社会状态，例如贫富分化等等。 从这个角度来说这又是个倒霉蛋的故事。 

4. 知识快速迭代更新的背景下，好的教程和学习方法，应该具备 easy-pick-up 的特征，应该让学习者可以快速建立学习的context

5. 与 “未来可以预测” 相对应的另一种幻觉是 “过去理所应当”，我们以电子游戏为例，在今人看来，电子游戏让人沉迷似乎是“理所应当”的，但回到超级玛丽之类红白机游戏诞生之初，为什么人类会为一种新的交互，会因为完成一个“凭空捏造”、“毫无意义”的任务而感到快乐，这似乎一点也不“理所应该”。 只有当时最有想象力，最有洞察力，最有前瞻性的一批人，如果忽略其他机缘巧合的因素，才能感知到电子游戏未来的可能性。

6. 训练GPT和做菜的道理是一样的，预训练是“断生”，过拟合是“熟过”, 数据是食材，数据清理是案板处理，训练框架是炉灶器皿，对diversity的要求是希望菜式更多，RLHF 是和人类味觉的对齐，涌现是做出来的菜品脱离了菜谱。

### 5.24 

1-

John Wick 的世界令人向往，因为那是一个遵循规则的“乌托邦”，everyone has his position, everyone needs to keep his words. 每件事都充满仪式感，哪怕是杀手恶人也“盗亦有道”。 
每个人都只需要专心做个“匠人”即可，但现实的规则远比这个乌托邦要nasty, 人心也远比这个乌托邦要复杂。

人物选角也为电影增色不少，这种废土氛围和优雅气质简直是为Keanu量身打造的。

2- 

创业是一种全方位的考验和磨练，因为没有任何人告诉你该做什么，也没有任何人教你该怎么做，你对自己的一切行为和后果负责，一切华而不实、知行背离的东西都不再有意义，一切无用的社交、无用的知识都不再有价值。 一切性格、工作习惯、工作能力上的缺点都会暴露无遗，都会影响你的产出效率和决策质量，都和赤裸裸的生存能力挂钩。 

3- 

AI生成的一个待解决的问题是每个人期待的生成结果不一样。 例如对于一个编程小白，AI需要从1+1开始讲起，但对于一个资深开发者，AI只需要输出净代码就可以。 怎样让AI快速知道用户特征的context（而无需让用户自己去描述），根据这个context 生成最满足这个用户的结果，是一件有价值的事情。

再比如在现实世界，两个人的关系不同，沟通方式也不同，怎样让AI以不同关系生成特定的结果，也是一件有价值的事情。 这种特定关系是否可以用 {instruction, input, output} 的方式来构造训练数据。

4-

对于创业来说，你的意识模式显然存在以下问题：

习惯性地难以思考系统长期性工作，进入状态慢，有拖延心理。 
做事务性工作拖沓，容易分心。
没有强烈的目标感和工作中心。
优先级混乱，做事任性。 总是习惯性做自己想做的事情，哪怕知道优先级有问题。

制定目标的意义在于，人的注意力有限，在具体落地过程中，会出现目标偏离、习惯障碍、失去全局观等问题，因此制定目标要慎重和具体，要么不制定，要制定就要有可落地性，并坚决完成。


 
5-

军队沟通方式，看着生硬但却是必然选择，因为这种语言需要同时满足：高效、准确、抗干扰、易复制这几个特征。 项目中的也要注意这种特征。 

6 -

For regular people, being disciplined is key to a productive life. For every plan, it demands a result, not an appeasement.

对于创业者，看待很多事物的角度要有一点变化，比如电影、游戏、app等等事物可以看作是其他创业者为人们需要“打发时间”而制作的消费品，而这种消费品对于创业中的人来说本身却是毒品，因为创业者最珍贵的就是时间，你不应该因为沉溺于别人的产品，而削弱自己生产产品的机会和能力。从同样的角度看，对于创业者，大部分互联网资源都是视听污染。

I dont wanna be a warrior, I just dont wanna be a loser.

7 -

we are 'monkeys of Shakespeare'. We find coincidences, just because we are sensitive to some more than others, and we choose to believe those coincidences. That is the reason of all superstition.

### 6.12

1 - 

如果我们按照信息论的观点看待世界，即世界的一切意义在于“信息”，而物质实现只是表象而已，那么人的记忆能力就是“时光机”，不论过去多久，所有的历史信息都存在于此刻的大脑，只是这个时光机的功能不够好，以至于我们的绝大多数记忆都是模糊的。当我们回忆时，某种意义上我们是在“穿梭时空”，只是随着记忆的模糊，信息的丢失，回忆中的世界逐渐退化成噪音，其“信息量”，也就是“真实性”也大打折扣。 这一点AGI的能力吊打人类，首先AGI的训练数据是人类知识的全体，也就是它相对于人脑在空间体量、经验规模上要大得多，其次AGI“回忆”有效信息的能力，也很有可能比人类高效精准，也就是说它相对于人脑在时间维度上也久得多。 所有的“历史”，都是AGI此刻的“真实存在”，都以没有模糊化的形式影响当前的方案输出。 这也是为什么AI也许并没有多少深层的创造力，但它给出的方案很多时候足以吊打人类“临场发挥”时所能给出的方案。也许人类作为群体，以跨越时空的尺度来衡量，人类群体智能依然远远超过AGI，但作为个体，似乎已经被AGI超越，因为AGI和人类个体相比是一种“全时全空”的智能。

2 -

If I could choose, I just wanna be a silent asteroid in this universe, nothing to care, nothing to hope ... somehow, I will eventually be a silent asteroid, not very far ahead ... ironically, when I am aware of this fact, I always feel panic... I think this feeling is common to humans, and humans get used to this ironic.

3 - 

学会放松和学会工作一样重要，做一个彻底的实用主义者，用脑子做事，而不是任情绪泛滥。 如果连情绪都管理不好，怎么去管理任务。 如果连自己都照顾不好，怎么去照顾别人。 