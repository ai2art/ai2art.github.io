---
title:  Tenet of Diffusion Model
---

故事大纲

- 引子：DALLE 和 Imagen的神话
- 缘起：热力学第二定律
- 微光：微观可逆性
- 创世：VAE 和 GAN
- 辉煌：Diffusion Model的诞生

### 什么是扩散模型


让机器像人类一样创作文学作品和艺术作品，一直是工程师们的终极梦想之一。这其中的实用价值和哲学意义是不言而喻的。但对于这个目标是否能实现，各路道友们却看法不一。

在AI算法中，用来实现内容创作的叫做**生成模型**，这个名称主要是区别于传统的AI识别模型，例如物体识别、人脸识别。虽然从人类角度来看，似乎两种应用完全相反，但站在机器角度，可能差别没有那么大，因为从算法的本质而言，大家都是做数据拟合，所以模型的架构不论多么乱花渐欲迷人眼，它的本质还是**函数**，只是参数的多少有差别，函数的输出物有所差别。 输出二值或多值标签的就是“识别模型”，输出时间序列或者空间点阵信息的就是“生成模型”。 “大输入小输出”的就是**识别**，“小输入大输出”的就是**生成**，输入输出量级差不多就是灰色地带，例如机器翻译，站在人类应用的角度看，可能更像识别，但站在算法的角度来看和生成的差别很小。 由于本质的统一性，生成模型和识别模型的具体算法实现是可以彼此借鉴的。 作为后起之秀，生成模型从识别模型的研究经验中受益良多，尤其是在输入信息的**特征提取**层面。

 言归正传，聊聊我们的主角扩散模型。 如果你是做AI图形算法的，你可能知道，在扩散模型如日中天之前， VAE（变分自编码器）和出道比VAE稍晚的GAN （生成对抗网络） 才是生成模型中的香馍馍。

天下风云出我辈，一入江湖岁月催。 从传统模型（VAE、GAN等）向扩散模型的切换是不可逆的，原因有二：

1. 扩散模型的生成效果比传统模型要好很多
2. 扩散模型相对于传统模型来说，不是另辟蹊径，而是某种架构上的升级 

VAE、GAN这种以前的业界大佬，在巨兽扩散模型面前通常也只是某个中间层或者局部模块，当然这种升级并不是没有代价的，比如说：扩散模型对算力的消耗也大大升级了，最直接的结果是配置弱一点的电脑跑不动扩散模型，我那台显卡2G的笔记本只能望洋兴叹。 同时，推理的递进扩散机制，也大大降低了生成速度。从某个角度来说，扩散模型相对于传统生成模型是用时间换质量，怎样提高推理速度（例如模型蒸馏）是扩散模型需要解决的重要问题之一。

【to be continued】

不用担心机器抢饭碗，比如说这样的原创文章机器可能再过很长时间也写不出来。