---
title:  Tenet of Diffusion Model
draft: true
---

故事大纲

- 引子：DALLE 和 Imagen的神话
- 缘起：热力学第二定律
- 微光：微观可逆性
- 创世：VAE 和 GAN
- 辉煌：Diffusion Model的诞生

### 什么是扩散模型


科技是现实世界最接近魔法的事物，而让机器像人类一样创作文学作品和艺术作品，一直是工程师们的奇幻梦想之一。这其中的实用价值和哲学意义是不言而喻的。但对于这个目标是否最终能实现，许多工程师们并不看好，但扩散模型的出现让我们看到了希望。

扩散模型属于**生成模型**的一种，在机器学习领域，人们将实现内容创作功能的一类算法统称为**生成模型**。这个名称主要是为了区别于传统的**识别模型**，例如物体识别、人脸识别。虽然从应用角度来看，似乎两种功能完全相反，但站在机器的角度，可能差别没有那么大，因为从机器学习的本质而言，大家都是做数据拟合，所以模型的架构不论多么乱花渐欲迷人眼，它的本质还是**函数**，只是参数的多少有差别，函数的输出物有所差别。 输出二值或多值标签的就是“识别模型”，输出时间序列或者空间点阵信息的就是“生成模型”。 “大输入小输出”的就是**识别**，“小输入大输出”的就是**生成**，输入输出量级差不多就是灰色地带，例如机器翻译，站在人类应用的角度看，可能更像识别，但站在算法的角度来看和生成的差别很小。 由于本质的统一性，生成模型和识别模型的具体算法实现是可以彼此借鉴的。 作为后起之秀，生成模型从识别模型的研究经验中受益良多，尤其是在输入信息的**特征提取**层面。


江山代有人才出，一入江湖岁月催。 我们知道在扩散模型如日中天之前， VAE（变分自编码器）和出道比VAE稍晚的GAN （生成对抗网络） 才是生成模型中的香馍馍。

为什么LDM（扩散模型）会取代之前的VAE或GAN呢，当然最主要的原因是生成效果比传统模型要好很多。这种取代是不可逆的，因为扩散模型相对于传统模型来说，不是另辟蹊径，而是某种架构上的升级。

VAE、GAN这种以前独当一面的模型，在扩散模型面前也只相当于某个中间层或者局部模块，当然这种升级并不是没有代价的，这主要体现在扩散模型对算力的消耗也大大升级了，最直接的结果是配置弱一点的电脑跑不动扩散模型，我那台显卡2G的笔记本只能望洋兴叹。 同时，推理的递进扩散机制（后面会详细讲解），也限制了生成的速度。从某个角度来说，扩散模型相对于传统生成模型是用时间换质量，怎样提高推理速度是扩散模型需要解决的重要问题。

言归正传，现在假设你没有任何先验知识，让你来设计一个模型可以生成各式各样的卡通人物，你会怎么做呢。对于计算机来说，“生成”有一个更专业的术语叫“采样”。 所以我们有

问题1： 怎样采样卡通人物图像？

面对这个问题，计算机首先会一脸懵（它不是“阿拉丁灯神”），因为计算机不知道“卡通人物”的概率分布是怎样的，所以它不知道该如何采样出一个卡通人物。

计算机只能采样一个概率分布已经明确给定的对象，比如说，你可以让计算机采样一个平均分布或者正态分布。 所以让我们换个问题

问题2： 我们采样某个给定的正态分布，得到了一个样本点 $x$，那么怎样找到这个样本点对应的卡通图像 $y$?

这个提法本身没有多少信息量，但却把一个模糊的问题变得更具体了，也就是说我们现在要找到一个函数 $y = f(x)$, 可以把随机分布的样本点映射为卡通人物的样本点 $y$，于是我们有

问题3： 怎样找到一个函数$f(\cdot)$可以把随机分布的样本点$x$, 映射为卡通人物的样本点$y$ ?

我们最终找到了一个正确的问题。 一个好的问题，就是答案的一半。 对于问题3，VAE和GAN分别给出了自己的答案。 篇幅所限，这里先不展开讨论VAE和GAN，而扩散模型给出的基本思路是：

给定一个卡通人物的数据集作为训练数据，我们首先朝数据集中的图像 $y$ 一点一点添加“噪声”（正向扩散过程），最终把图像“破坏”成一个完全随机的纹理 $x$（注意：这个随机纹理可以看作是随机分布的一个样本点），然后我们通过机器学习，得到一个函数$f(\cdot)$, 这个函数可以从随机纹理$x$ 出发，一点一点把之前添加的噪声去除，最终得到最初的图像（逆向扩散过程）

这个思路的完整工程实现，我们放到进阶篇。 下面我们来看看扩散模型到底能做什么。

a history review of diffusion model ....



【to be continued】

不用担心机器抢饭碗，比如说这样的原创文章机器可能再过很长时间也写不出来。